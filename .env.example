# LLM Configuration (OpenAI-compatible protocol)
# Supports: OpenAI, litellm proxy, Ollama, Azure OpenAI, vLLM, etc.
LLM_API_KEY=sk-your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=8000
LLM_MAX_RETRIES=3
# Thinking mode: "auto" (detect from model), "native", or "app"
LLM_THINKING_MODE=auto
# Reasoning effort for native thinking models: "low", "medium", or "high" (default: "medium")
# LLM_REASONING_EFFORT=medium
# Tool call mode: "auto" (detect from model), "fc" (function calling), or "yaml" (text parsing)
LLM_TOOL_CALL_MODE=auto

# Agent step limit (default: 40, min: 5, max: 200)
# AGENT_MAX_STEPS=40

# Web Server
WEB_PORT=8080

# Workspace — Agent's working directory (root for file tools)
# Leave empty to use the current directory where the program is launched
# WORKSPACE_DIR=/path/to/your/project

# Search Tools — auto-enabled when API key is set, disabled when empty
# TAVILY_API_KEY=tvly-your-key-here
# BRAVE_API_KEY=BSA-your-key-here
