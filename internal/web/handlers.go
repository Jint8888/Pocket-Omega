package web

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"strings"
	"time"

	"github.com/pocketomega/pocket-omega/internal/agent"
	"github.com/pocketomega/pocket-omega/internal/core"
	"github.com/pocketomega/pocket-omega/internal/llm"
	"github.com/pocketomega/pocket-omega/internal/prompt"
	"github.com/pocketomega/pocket-omega/internal/session"
	"github.com/pocketomega/pocket-omega/internal/thinking"
	"github.com/pocketomega/pocket-omega/internal/tool"
)

const (
	maxRequestBody  = 1 << 20         // 1MB max request body
	maxMessageRunes = 8000            // max user message length in runes
	chatTimeout     = 5 * time.Minute // global timeout for chat flow
	agentTimeout    = 5 * time.Minute // global timeout for agent flow
)

// â”€â”€ SSE Writer â”€â”€

// sseWriter wraps an http.ResponseWriter with SSE event writing and
// client disconnect detection. Shared by both Chat and Agent handlers.
type sseWriter struct {
	w       http.ResponseWriter
	flusher http.Flusher
	ctx     context.Context
}

// newSSEWriter prepares SSE headers and returns a writer.
// Returns nil if streaming is not supported.
func newSSEWriter(w http.ResponseWriter, r *http.Request) *sseWriter {
	flusher, ok := w.(http.Flusher)
	if !ok {
		http.Error(w, "Streaming not supported", http.StatusInternalServerError)
		return nil
	}

	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("X-Accel-Buffering", "no")

	return &sseWriter{w: w, flusher: flusher, ctx: r.Context()}
}

// Send writes an SSE event. Returns false if the client has disconnected.
func (s *sseWriter) Send(event string, data interface{}) bool {
	select {
	case <-s.ctx.Done():
		return false
	default:
	}
	jsonBytes, err := json.Marshal(data)
	if err != nil {
		log.Printf("[SSE] JSON marshal error: %v", err)
		return false
	}
	if _, err := fmt.Fprintf(s.w, "event: %s\ndata: %s\n\n", event, string(jsonBytes)); err != nil {
		log.Printf("[SSE] Write error (client disconnected?): %v", err)
		return false
	}
	s.flusher.Flush()
	return true
}

// â”€â”€ Shared Solution Formatter â”€â”€

// formatSolutionPromptDefault is the fallback system prompt for the solution
// formatting step used when no loader is available or answer_style.md is absent.
const formatSolutionPromptDefault = `ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆæ•´ç†åŠ©æ‰‹ã€‚å°†æ¨ç†ç»“è®ºæ•´ç†ä¸ºæ¸…æ™°ã€å‹å¥½çš„æœ€ç»ˆå›ç­”ã€‚

## é£æ ¼æŒ‡å—
- æ­¥éª¤/æ–¹æ¡ˆç”¨æœ‰åºåˆ—è¡¨ï¼Œè¦ç‚¹ç”¨æ— åºåˆ—è¡¨
- é‡ç‚¹å…³é”®è¯ç”¨ **åŠ ç²—**
- ä»£ç /å‘½ä»¤ç”¨ä»£ç å—
- ä¿æŒè¯­è¨€ä¸ç”¨æˆ·ä¸€è‡´ï¼ˆä¸­æ–‡é—®ç”¨ä¸­æ–‡ç­”ï¼‰
- ä¸è¦æ·»åŠ "ä»¥ä¸‹æ˜¯ç­”æ¡ˆ"ä¹‹ç±»çš„å‰ç¼€ï¼Œç›´æ¥ä½œç­”
- å¦‚æœåŸå§‹ç»“è®ºå·²è¶³å¤Ÿå¥½ï¼Œç›´æ¥ä¿ç•™ä¸è¦è¿‡åº¦ä¿®é¥°

## ç¤ºä¾‹

ç”¨æˆ·é—®é¢˜ï¼šä¸€ä¸ªæˆ¿é—´é‡Œæœ‰3ç›ç¯ï¼Œæˆ¿é—´å¤–æœ‰3ä¸ªå¼€å…³ã€‚ä½ åªèƒ½è¿›å…¥æˆ¿é—´ä¸€æ¬¡ã€‚å¦‚ä½•ç¡®å®šå“ªä¸ªå¼€å…³æ§åˆ¶å“ªç›ç¯ï¼Ÿ

æ•´ç†åçš„ç­”æ¡ˆï¼š

ğŸ’¡ **æ ¸å¿ƒæ€è·¯ï¼š** åˆ©ç”¨ç¯æ³¡é€šç”µåçš„ **çƒ­æƒ°æ€§** å¼•å…¥ç¬¬ä¸‰ä¸ªåˆ¤æ–­ç»´åº¦ã€‚

ğŸ“ **æ“ä½œæ­¥éª¤ï¼š**

1. **æ‰“å¼€å¼€å…³ 1**ï¼Œä¿æŒçº¦ 5 åˆ†é’Ÿï¼Œè®©ç¯æ³¡å……åˆ†å‘çƒ­
2. **å…³é—­å¼€å…³ 1**ï¼Œç«‹å³ **æ‰“å¼€å¼€å…³ 2**
3. **è¿›å…¥æˆ¿é—´**ï¼Œè§‚å¯Ÿå¹¶è§¦æ‘¸ç¯æ³¡

ğŸ” **åˆ¤æ–­æ–¹æ³•ï¼š**

- ğŸ’¡ **äº®ç€çš„ç¯** â†’ å¼€å…³ 2 æ§åˆ¶ï¼ˆå½“å‰é€šç”µï¼‰
- ğŸ”¥ **ä¸äº®ä½†æ¸©çƒ­** â†’ å¼€å…³ 1 æ§åˆ¶ï¼ˆåˆšæ–­ç”µï¼Œä½™æ¸©å°šåœ¨ï¼‰
- â„ï¸ **ä¸äº®ä¸”å†°å‡‰** â†’ å¼€å…³ 3 æ§åˆ¶ï¼ˆä»æœªé€šç”µï¼‰

âœ… å…³é”®åœ¨äºåˆ©ç”¨ç¯æ³¡çš„çƒ­æƒ°æ€§ï¼Œå°†"åªèƒ½è¿›ä¸€æ¬¡"çš„ä¸¤æ€åˆ¤æ–­ï¼ˆäº®/ç­ï¼‰æ‰©å±•ä¸ºä¸‰æ€åˆ¤æ–­ï¼ˆäº®/æš—çƒ­/æš—å†·ï¼‰ã€‚`

// buildFormatPrompt assembles the system prompt for the solution formatting step.
// Uses answer_style.md from loader (L2+L3) when available.
func buildFormatPrompt(loader *prompt.PromptLoader) string {
	if loader == nil {
		return formatSolutionPromptDefault
	}

	style := loader.Load("answer_style.md")
	if style == "" {
		return formatSolutionPromptDefault
	}

	// L2 style + L3 user rules
	var sb strings.Builder
	sb.WriteString("ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆæ•´ç†åŠ©æ‰‹ã€‚å°†æ¨ç†ç»“è®ºæ•´ç†ä¸ºæ¸…æ™°ã€å‹å¥½çš„æœ€ç»ˆå›ç­”ã€‚\n\n")
	sb.WriteString(style)
	if rules := loader.LoadUserRules(); rules != "" {
		sb.WriteString("\n\n## ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™\n")
		sb.WriteString(rules)
	}
	return sb.String()
}

// formatSolution makes a lightweight LLM call to clean and organize
// a raw conclusion into a well-structured, user-facing answer.
// Shared by both ChatHandler and AgentHandler.
func formatSolution(ctx context.Context, provider llm.LLMProvider, loader *prompt.PromptLoader, problem, rawSolution string) (string, error) {
	userPrompt := fmt.Sprintf("ç”¨æˆ·é—®é¢˜ï¼š%s\n\nåŸå§‹æ¨ç†ç»“è®ºï¼š\n%s\n\nè¯·æ•´ç†ä¸ºæœ€ç»ˆç­”æ¡ˆï¼š", problem, rawSolution)

	resp, err := provider.CallLLM(ctx, []llm.Message{
		{Role: llm.RoleSystem, Content: buildFormatPrompt(loader)},
		{Role: llm.RoleUser, Content: userPrompt},
	})
	if err != nil {
		return "", fmt.Errorf("format LLM call failed: %w", err)
	}

	formatted := strings.TrimSpace(resp.Content)
	if formatted == "" {
		return "", fmt.Errorf("format returned empty response")
	}

	log.Printf("[Format] Formatted solution: %d -> %d chars", len(rawSolution), len(formatted))
	return formatted, nil
}

// â”€â”€ SSE Event Types â”€â”€

type sseThoughtEvent struct {
	ThoughtNumber   int    `json:"thought_number"`
	CurrentThinking string `json:"current_thinking"`
	PlanText        string `json:"plan_text,omitempty"`
}

type sseDoneEvent struct {
	Solution string `json:"solution"`
}

type sseErrorEvent struct {
	Error string `json:"error"`
}

// â”€â”€ Chat Handler â”€â”€

// ChatHandler handles chat requests and runs the CoT flow.
type ChatHandler struct {
	llmProvider         llm.LLMProvider
	maxRetries          int
	contextWindowTokens int
	sessionStore        *session.Store
	loader              *prompt.PromptLoader
}

// NewChatHandler creates a new handler with the given LLM provider.
// loader is optional (nil is valid) â€” falls back to hardcoded defaults.
func NewChatHandler(provider llm.LLMProvider, maxRetries int, contextWindowTokens int, store *session.Store, loader *prompt.PromptLoader) *ChatHandler {
	return &ChatHandler{
		llmProvider:         provider,
		maxRetries:          maxRetries,
		contextWindowTokens: contextWindowTokens,
		sessionStore:        store,
		loader:              loader,
	}
}

// HandleChat processes chat POST requests using SSE streaming.
func (h *ChatHandler) HandleChat(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	r.Body = http.MaxBytesReader(w, r.Body, maxRequestBody)

	userMsg := strings.TrimSpace(r.FormValue("message"))
	if userMsg == "" {
		http.Error(w, "Empty message", http.StatusBadRequest)
		return
	}
	if len([]rune(userMsg)) > maxMessageRunes {
		http.Error(w, "Message too long", http.StatusRequestEntityTooLarge)
		return
	}

	log.Printf("[Chat] Received: %s", userMsg)

	// Session history lookup
	sessionID := strings.TrimSpace(r.FormValue("session_id"))
	var historyMsgs []llm.Message
	if sessionID != "" && h.sessionStore != nil {
		turns := h.sessionStore.GetHistory(sessionID)
		// Allocate 50% of context window (in chars) to chat history.
		// More generous than Agent's 30% since Chat has no tool output overhead.
		// When contextWindowTokens is 0 (unknown), budget is 0 (no cap).
		budget := h.contextWindowTokens * 2 * 50 / 100
		historyMsgs = session.ToMessages(turns, budget)
	}

	sse := newSSEWriter(w, r)
	if sse == nil {
		return
	}

	// Global timeout for the chat flow
	ctx, cancel := context.WithTimeout(r.Context(), chatTimeout)
	defer cancel()

	// Build and run the CoT flow with streaming callback
	flow := thinking.BuildFlow(h.llmProvider, h.maxRetries)
	state := &thinking.ThinkingState{
		Problem:             userMsg,
		ConversationHistory: historyMsgs,
		OnThoughtComplete: func(thought thinking.ThoughtData) {
			sse.Send("thought", sseThoughtEvent{
				ThoughtNumber:   thought.ThoughtNumber,
				CurrentThinking: strings.TrimSpace(thought.CurrentThinking),
				PlanText:        thinking.FormatPlan(thought.Planning, 0),
			})
		},
	}
	flow.Run(ctx, state)

	solution := strings.TrimSpace(state.Solution)
	if solution == "" {
		solution = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›ç­”ã€‚è¯·é‡è¯•ã€‚"
	} else {
		formatted, err := formatSolution(ctx, h.llmProvider, h.loader, userMsg, solution)
		if err != nil {
			log.Printf("[Format] Formatting failed, using raw solution: %v", err)
		} else {
			solution = formatted
		}
	}

	sse.Send("done", sseDoneEvent{Solution: solution})
	log.Printf("[Chat] Done: %d thoughts, solution %d chars", len(state.Thoughts), len(solution))

	// Persist this turn to session history
	if sessionID != "" && h.sessionStore != nil {
		h.sessionStore.AppendTurn(sessionID, session.Turn{
			UserMsg:   userMsg,
			Assistant: solution,
			IsAgent:   false,
		})
	}
}

// â”€â”€ Agent Handler (Phase 2) â”€â”€

// AgentHandler handles agent requests with tool usage capability.
type AgentHandler struct {
	llmProvider         llm.LLMProvider
	agentFlow           core.Workflow[agent.AgentState]
	toolRegistry        *tool.Registry
	workspaceDir        string
	execLogger          *agent.ExecLogger
	thinkingMode        string
	toolCallMode        string
	contextWindowTokens int
	sessionStore        *session.Store
	loader              *prompt.PromptLoader
}

// NewAgentHandler creates a new agent handler.
// loader is optional (nil is valid) â€” nodes fall back to hardcoded defaults.
func NewAgentHandler(provider llm.LLMProvider, registry *tool.Registry, workspaceDir string, execLogger *agent.ExecLogger, thinkingMode string, toolCallMode string, contextWindowTokens int, store *session.Store, loader *prompt.PromptLoader) *AgentHandler {
	return &AgentHandler{
		llmProvider:         provider,
		agentFlow:           agent.BuildAgentFlow(provider, registry, thinkingMode, loader),
		toolRegistry:        registry,
		workspaceDir:        workspaceDir,
		execLogger:          execLogger,
		thinkingMode:        thinkingMode,
		toolCallMode:        toolCallMode,
		contextWindowTokens: contextWindowTokens,
		sessionStore:        store,
		loader:              loader,
	}
}

// HandleAgent processes agent requests using SSE streaming with tool calls.
func (h *AgentHandler) HandleAgent(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	r.Body = http.MaxBytesReader(w, r.Body, maxRequestBody)

	userMsg := strings.TrimSpace(r.FormValue("message"))
	if userMsg == "" {
		http.Error(w, "Empty message", http.StatusBadRequest)
		return
	}
	if len([]rune(userMsg)) > maxMessageRunes {
		http.Error(w, "Message too long", http.StatusRequestEntityTooLarge)
		return
	}

	log.Printf("[Agent] Received: %s", userMsg)

	// Session history lookup
	sessionID := strings.TrimSpace(r.FormValue("session_id"))
	var historyPrefix string
	if sessionID != "" && h.sessionStore != nil {
		turns := h.sessionStore.GetHistory(sessionID)
		// allocate 30% of context window (in chars) to conversation history
		budget := h.contextWindowTokens * 2 * 30 / 100
		historyPrefix = session.ToProblemPrefix(turns, budget)
	}

	sse := newSSEWriter(w, r)
	if sse == nil {
		return
	}

	// Global timeout for the entire agent flow
	ctx, cancel := context.WithTimeout(r.Context(), agentTimeout)
	defer cancel()

	// Send immediate status so user sees instant feedback
	sse.Send("status", map[string]string{"message": "ğŸ¤” æ­£åœ¨åˆ†æé—®é¢˜..."})

	// Start execution log session
	if h.execLogger != nil {
		h.execLogger.StartSession(userMsg)
	}

	// Build agent state with SSE callback
	state := &agent.AgentState{
		Problem:             userMsg,
		ConversationHistory: historyPrefix,
		WorkspaceDir:        h.workspaceDir,
		ToolRegistry:        h.toolRegistry,
		ThinkingMode:        h.thinkingMode,
		ToolCallMode:        h.toolCallMode,
		ContextWindowTokens: h.contextWindowTokens,
		OnStepComplete: func(step agent.StepRecord) {
			// Write to execution log
			if h.execLogger != nil {
				h.execLogger.LogStep(step)
			}
			switch step.Type {
			case "decide":
				sse.Send("step", step)
			case "tool":
				sse.Send("tool", step)
			case "think":
				sse.Send("step", step)
			}
		},
		OnStreamChunk: func(chunk string) {
			sse.Send("chunk", map[string]string{"text": chunk})
		},
	}

	// Run the agent flow with timeout context
	h.agentFlow.Run(ctx, state)

	// AnswerNode already synthesizes a polished answer with LLM.
	// Skip formatSolution here to avoid a redundant LLM round-trip
	// that adds 3-5s of latency with no visible benefit.
	solution := strings.TrimSpace(state.Solution)
	if solution == "" {
		solution = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›ç­”ã€‚è¯·é‡è¯•ã€‚"
	}

	sse.Send("done", sseDoneEvent{Solution: solution})
	log.Printf("[Agent] Done: %d steps, solution %d chars", len(state.StepHistory), len(solution))

	// Write execution log summary
	if h.execLogger != nil {
		h.execLogger.EndSession(state)
	}

	// Persist this turn to session history
	if sessionID != "" && h.sessionStore != nil {
		h.sessionStore.AppendTurn(sessionID, session.Turn{
			UserMsg:   userMsg,
			Assistant: solution,
			IsAgent:   true,
		})
	}
}
