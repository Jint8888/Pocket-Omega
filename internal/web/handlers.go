package web

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"strings"
	"time"

	"github.com/pocketomega/pocket-omega/internal/agent"
	"github.com/pocketomega/pocket-omega/internal/core"
	"github.com/pocketomega/pocket-omega/internal/llm"
	"github.com/pocketomega/pocket-omega/internal/plan"
	"github.com/pocketomega/pocket-omega/internal/prompt"
	"github.com/pocketomega/pocket-omega/internal/session"
	"github.com/pocketomega/pocket-omega/internal/thinking"
	"github.com/pocketomega/pocket-omega/internal/tool"
	"github.com/pocketomega/pocket-omega/internal/tool/builtin"
)

const (
	maxRequestBody  = 1 << 20         // 1MB max request body
	maxMessageRunes = 8000            // max user message length in runes
	chatTimeout     = 5 * time.Minute // global timeout for chat flow
	agentTimeout    = 5 * time.Minute // global timeout for agent flow
)

// â”€â”€ SSE Writer â”€â”€

// sseWriter wraps an http.ResponseWriter with SSE event writing and
// client disconnect detection. Shared by both Chat and Agent handlers.
type sseWriter struct {
	w       http.ResponseWriter
	flusher http.Flusher
	ctx     context.Context
}

// newSSEWriter prepares SSE headers and returns a writer.
// Returns nil if streaming is not supported.
func newSSEWriter(w http.ResponseWriter, r *http.Request) *sseWriter {
	flusher, ok := w.(http.Flusher)
	if !ok {
		http.Error(w, "Streaming not supported", http.StatusInternalServerError)
		return nil
	}

	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("X-Accel-Buffering", "no")

	return &sseWriter{w: w, flusher: flusher, ctx: r.Context()}
}

// Send writes an SSE event. Returns false if the client has disconnected.
func (s *sseWriter) Send(event string, data interface{}) bool {
	select {
	case <-s.ctx.Done():
		return false
	default:
	}
	jsonBytes, err := json.Marshal(data)
	if err != nil {
		log.Printf("[SSE] JSON marshal error: %v", err)
		return false
	}
	if _, err := fmt.Fprintf(s.w, "event: %s\ndata: %s\n\n", event, string(jsonBytes)); err != nil {
		log.Printf("[SSE] Write error (client disconnected?): %v", err)
		return false
	}
	s.flusher.Flush()
	return true
}

// â”€â”€ Shared Solution Formatter â”€â”€

// formatSolutionPromptDefault is the fallback system prompt for the solution
// formatting step used when no loader is available or answer_style.md is absent.
const formatSolutionPromptDefault = `ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆæ•´ç†åŠ©æ‰‹ã€‚å°†æŽ¨ç†ç»“è®ºæ•´ç†ä¸ºæ¸…æ™°ã€å‹å¥½çš„æœ€ç»ˆå›žç­”ã€‚

## é£Žæ ¼æŒ‡å—
- æ­¥éª¤/æ–¹æ¡ˆç”¨æœ‰åºåˆ—è¡¨ï¼Œè¦ç‚¹ç”¨æ— åºåˆ—è¡¨
- é‡ç‚¹å…³é”®è¯ç”¨ **åŠ ç²—**
- ä»£ç /å‘½ä»¤ç”¨ä»£ç å—
- ä¿æŒè¯­è¨€ä¸Žç”¨æˆ·ä¸€è‡´ï¼ˆä¸­æ–‡é—®ç”¨ä¸­æ–‡ç­”ï¼‰
- ä¸è¦æ·»åŠ "ä»¥ä¸‹æ˜¯ç­”æ¡ˆ"ä¹‹ç±»çš„å‰ç¼€ï¼Œç›´æŽ¥ä½œç­”
- å¦‚æžœåŽŸå§‹ç»“è®ºå·²è¶³å¤Ÿå¥½ï¼Œç›´æŽ¥ä¿ç•™ä¸è¦è¿‡åº¦ä¿®é¥°

## ç¤ºä¾‹

ç”¨æˆ·é—®é¢˜ï¼šä¸€ä¸ªæˆ¿é—´é‡Œæœ‰3ç›ç¯ï¼Œæˆ¿é—´å¤–æœ‰3ä¸ªå¼€å…³ã€‚ä½ åªèƒ½è¿›å…¥æˆ¿é—´ä¸€æ¬¡ã€‚å¦‚ä½•ç¡®å®šå“ªä¸ªå¼€å…³æŽ§åˆ¶å“ªç›ç¯ï¼Ÿ

æ•´ç†åŽçš„ç­”æ¡ˆï¼š

ðŸ’¡ **æ ¸å¿ƒæ€è·¯ï¼š** åˆ©ç”¨ç¯æ³¡é€šç”µåŽçš„ **çƒ­æƒ°æ€§** å¼•å…¥ç¬¬ä¸‰ä¸ªåˆ¤æ–­ç»´åº¦ã€‚

ðŸ“ **æ“ä½œæ­¥éª¤ï¼š**

1. **æ‰“å¼€å¼€å…³ 1**ï¼Œä¿æŒçº¦ 5 åˆ†é’Ÿï¼Œè®©ç¯æ³¡å……åˆ†å‘çƒ­
2. **å…³é—­å¼€å…³ 1**ï¼Œç«‹å³ **æ‰“å¼€å¼€å…³ 2**
3. **è¿›å…¥æˆ¿é—´**ï¼Œè§‚å¯Ÿå¹¶è§¦æ‘¸ç¯æ³¡

ðŸ” **åˆ¤æ–­æ–¹æ³•ï¼š**

- ðŸ’¡ **äº®ç€çš„ç¯** â†’ å¼€å…³ 2 æŽ§åˆ¶ï¼ˆå½“å‰é€šç”µï¼‰
- ðŸ”¥ **ä¸äº®ä½†æ¸©çƒ­** â†’ å¼€å…³ 1 æŽ§åˆ¶ï¼ˆåˆšæ–­ç”µï¼Œä½™æ¸©å°šåœ¨ï¼‰
- â„ï¸ **ä¸äº®ä¸”å†°å‡‰** â†’ å¼€å…³ 3 æŽ§åˆ¶ï¼ˆä»Žæœªé€šç”µï¼‰

âœ… å…³é”®åœ¨äºŽåˆ©ç”¨ç¯æ³¡çš„çƒ­æƒ°æ€§ï¼Œå°†"åªèƒ½è¿›ä¸€æ¬¡"çš„ä¸¤æ€åˆ¤æ–­ï¼ˆäº®/ç­ï¼‰æ‰©å±•ä¸ºä¸‰æ€åˆ¤æ–­ï¼ˆäº®/æš—çƒ­/æš—å†·ï¼‰ã€‚`

// buildFormatPrompt assembles the system prompt for the solution formatting step.
// Uses answer_style.md from loader (L2+L3) when available.
func buildFormatPrompt(loader *prompt.PromptLoader) string {
	if loader == nil {
		return formatSolutionPromptDefault
	}

	style := loader.Load("answer_style.md")
	if style == "" {
		return formatSolutionPromptDefault
	}

	// L2 style + L3 user rules
	var sb strings.Builder
	sb.WriteString("ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆæ•´ç†åŠ©æ‰‹ã€‚å°†æŽ¨ç†ç»“è®ºæ•´ç†ä¸ºæ¸…æ™°ã€å‹å¥½çš„æœ€ç»ˆå›žç­”ã€‚\n\n")
	sb.WriteString(style)
	if rules := loader.LoadUserRules(); rules != "" {
		sb.WriteString("\n\n## ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™\n")
		sb.WriteString(rules)
	}
	return sb.String()
}

// formatSolution makes a lightweight LLM call to clean and organize
// a raw conclusion into a well-structured, user-facing answer.
// Shared by both ChatHandler and AgentHandler.
func formatSolution(ctx context.Context, provider llm.LLMProvider, loader *prompt.PromptLoader, problem, rawSolution string) (string, error) {
	userPrompt := fmt.Sprintf("ç”¨æˆ·é—®é¢˜ï¼š%s\n\nåŽŸå§‹æŽ¨ç†ç»“è®ºï¼š\n%s\n\nè¯·æ•´ç†ä¸ºæœ€ç»ˆç­”æ¡ˆï¼š", problem, rawSolution)

	resp, err := provider.CallLLM(ctx, []llm.Message{
		{Role: llm.RoleSystem, Content: buildFormatPrompt(loader)},
		{Role: llm.RoleUser, Content: userPrompt},
	})
	if err != nil {
		return "", fmt.Errorf("format LLM call failed: %w", err)
	}

	formatted := strings.TrimSpace(resp.Content)
	if formatted == "" {
		return "", fmt.Errorf("format returned empty response")
	}

	log.Printf("[Format] Formatted solution: %d -> %d chars", len(rawSolution), len(formatted))
	return formatted, nil
}

// â”€â”€ SSE Event Types â”€â”€

type sseThoughtEvent struct {
	ThoughtNumber   int    `json:"thought_number"`
	CurrentThinking string `json:"current_thinking"`
	PlanText        string `json:"plan_text,omitempty"`
}

type sseDoneEvent struct {
	Solution string `json:"solution"`
}

type sseErrorEvent struct {
	Error string `json:"error"`
}

const sseEventPlan = "plan"

type ssePlanEvent struct {
	Steps []plan.PlanStep `json:"steps"`
}

// â”€â”€ Chat Handler â”€â”€

// ChatHandler handles chat requests and runs the CoT flow.
type ChatHandler struct {
	llmProvider         llm.LLMProvider
	maxRetries          int
	contextWindowTokens int
	sessionStore        *session.Store
	loader              *prompt.PromptLoader
}

// NewChatHandler creates a new handler with the given LLM provider.
// loader is optional (nil is valid) â€” falls back to hardcoded defaults.
func NewChatHandler(provider llm.LLMProvider, maxRetries int, contextWindowTokens int, store *session.Store, loader *prompt.PromptLoader) *ChatHandler {
	return &ChatHandler{
		llmProvider:         provider,
		maxRetries:          maxRetries,
		contextWindowTokens: contextWindowTokens,
		sessionStore:        store,
		loader:              loader,
	}
}

// HandleChat processes chat POST requests using SSE streaming.
func (h *ChatHandler) HandleChat(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	r.Body = http.MaxBytesReader(w, r.Body, maxRequestBody)

	userMsg := strings.TrimSpace(r.FormValue("message"))
	if userMsg == "" {
		http.Error(w, "Empty message", http.StatusBadRequest)
		return
	}
	if len([]rune(userMsg)) > maxMessageRunes {
		http.Error(w, "Message too long", http.StatusRequestEntityTooLarge)
		return
	}

	log.Printf("[Chat] Received: %s", userMsg)

	// Session history lookup
	sessionID := strings.TrimSpace(r.FormValue("session_id"))
	var historyMsgs []llm.Message
	if sessionID != "" && h.sessionStore != nil {
		turns, summary := h.sessionStore.GetSessionContext(sessionID)
		// Allocate 50% of context window (in chars) to chat history.
		// More generous than Agent's 30% since Chat has no tool output overhead.
		// When contextWindowTokens is 0 (unknown), budget is 0 (no cap).
		budget := h.contextWindowTokens * 2 * 50 / 100
		historyMsgs = session.ToMessages(turns, budget, summary)
	}

	sse := newSSEWriter(w, r)
	if sse == nil {
		return
	}

	// Global timeout for the chat flow
	ctx, cancel := context.WithTimeout(r.Context(), chatTimeout)
	defer cancel()

	// Build and run the CoT flow with streaming callback
	flow := thinking.BuildFlow(h.llmProvider, h.maxRetries)
	state := &thinking.ThinkingState{
		Problem:             userMsg,
		ConversationHistory: historyMsgs,
		OnThoughtComplete: func(thought thinking.ThoughtData) {
			sse.Send("thought", sseThoughtEvent{
				ThoughtNumber:   thought.ThoughtNumber,
				CurrentThinking: strings.TrimSpace(thought.CurrentThinking),
				PlanText:        thinking.FormatPlan(thought.Planning, 0),
			})
		},
	}
	flow.Run(ctx, state)

	solution := strings.TrimSpace(state.Solution)
	if solution == "" {
		solution = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›žç­”ã€‚è¯·é‡è¯•ã€‚"
	} else {
		// ChatHandler uses ThinkingFlow which has no AnswerNode â€” the raw CoT
		// conclusion needs a formatting pass to produce a polished user-facing answer.
		// (AgentHandler skips this step because its AnswerNode already synthesizes
		// the final response with an LLM call, making a second pass redundant.)
		formatted, err := formatSolution(ctx, h.llmProvider, h.loader, userMsg, solution)
		if err != nil {
			log.Printf("[Format] Formatting failed, using raw solution: %v", err)
		} else {
			solution = formatted
		}
	}

	sse.Send("done", sseDoneEvent{Solution: solution})
	log.Printf("[Chat] Done: %d thoughts, solution %d chars", len(state.Thoughts), len(solution))

	// Persist this turn to session history
	if sessionID != "" && h.sessionStore != nil {
		h.sessionStore.AppendTurn(sessionID, session.Turn{
			UserMsg:   userMsg,
			Assistant: solution,
			IsAgent:   false,
		})
	}
}

// â”€â”€ Agent Handler (Phase 2) â”€â”€

// AgentHandlerOptions groups all configuration for AgentHandler.
// Use this instead of positional parameters to keep NewAgentHandler maintainable
// as new options are added over time.
type AgentHandlerOptions struct {
	Provider            llm.LLMProvider
	Registry            *tool.Registry
	WorkspaceDir        string
	ExecLogger          *agent.ExecLogger
	ThinkingMode        string
	ToolCallMode        string
	ContextWindowTokens int
	Store               *session.Store
	Loader              *prompt.PromptLoader // optional â€” falls back to hardcoded defaults
	OSName              string               // e.g. "Windows" â€” for runtime info line
	ShellCmd            string               // e.g. "cmd.exe /c" â€” for runtime info line
	ModelName           string               // e.g. "gemini-2.5-pro" â€” for runtime info line
	PlanStore           *plan.PlanStore      // optional â€” enables update_plan tool
	MaxAgentTokens      int64                // 0 = disabled; CostGuard token budget
	MaxAgentDuration    time.Duration        // 0 = disabled; CostGuard time limit
}

// AgentHandler handles agent requests with tool usage capability.
type AgentHandler struct {
	llmProvider         llm.LLMProvider
	agentFlow           core.Workflow[agent.AgentState]
	toolRegistry        *tool.Registry
	workspaceDir        string
	execLogger          *agent.ExecLogger
	thinkingMode        string
	toolCallMode        string
	contextWindowTokens int
	sessionStore        *session.Store
	loader              *prompt.PromptLoader
	osName              string
	shellCmd            string
	modelName           string
	planStore           *plan.PlanStore
	maxAgentTokens      int64
	maxAgentDuration    time.Duration
}

// NewAgentHandler creates a new agent handler from AgentHandlerOptions.
func NewAgentHandler(opts AgentHandlerOptions) *AgentHandler {
	return &AgentHandler{
		llmProvider:         opts.Provider,
		agentFlow:           agent.BuildAgentFlow(opts.Provider, opts.Registry, opts.ThinkingMode, opts.Loader),
		toolRegistry:        opts.Registry,
		workspaceDir:        opts.WorkspaceDir,
		execLogger:          opts.ExecLogger,
		thinkingMode:        opts.ThinkingMode,
		toolCallMode:        opts.ToolCallMode,
		contextWindowTokens: opts.ContextWindowTokens,
		sessionStore:        opts.Store,
		loader:              opts.Loader,
		osName:              opts.OSName,
		shellCmd:            opts.ShellCmd,
		modelName:           opts.ModelName,
		planStore:           opts.PlanStore,
		maxAgentTokens:      opts.MaxAgentTokens,
		maxAgentDuration:    opts.MaxAgentDuration,
	}
}

// HandleAgent processes agent requests using SSE streaming with tool calls.
func (h *AgentHandler) HandleAgent(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	r.Body = http.MaxBytesReader(w, r.Body, maxRequestBody)

	userMsg := strings.TrimSpace(r.FormValue("message"))
	if userMsg == "" {
		http.Error(w, "Empty message", http.StatusBadRequest)
		return
	}
	if len([]rune(userMsg)) > maxMessageRunes {
		http.Error(w, "Message too long", http.StatusRequestEntityTooLarge)
		return
	}

	log.Printf("[Agent] Received: %s", userMsg)

	// Session history lookup
	sessionID := strings.TrimSpace(r.FormValue("session_id"))
	var historyPrefix string
	if sessionID != "" && h.sessionStore != nil {
		turns, summary := h.sessionStore.GetSessionContext(sessionID)
		// allocate 30% of context window (in chars) to conversation history
		budget := h.contextWindowTokens * 2 * 30 / 100
		historyPrefix = session.ToProblemPrefix(turns, budget, summary)
	}

	sse := newSSEWriter(w, r)
	if sse == nil {
		return
	}

	// Global timeout for the entire agent flow
	ctx, cancel := context.WithTimeout(r.Context(), agentTimeout)
	defer cancel()

	// Send immediate status so user sees instant feedback
	sse.Send("status", map[string]string{"message": "ðŸ¤” æ­£åœ¨åˆ†æžé—®é¢˜..."})

	// Start execution log session
	if h.execLogger != nil {
		h.execLogger.StartSession(userMsg)
	}

	// Per-request: create update_plan tool with session context + SSE callback.
	// Uses WithExtra to create a request-scoped registry copy â€” no mutation of global registry.
	reqRegistry := h.toolRegistry
	if h.planStore != nil {
		planTool := builtin.NewUpdatePlanTool(h.planStore, sessionID, func(steps []plan.PlanStep) {
			sse.Send(sseEventPlan, ssePlanEvent{Steps: steps})
		})
		reqRegistry = h.toolRegistry.WithExtra(planTool)
		// Clean up plan data after agent completes (synchronous â€” safe with current design).
		// If agent is ever moved to goroutine, move Delete to agent completion callback.
		defer h.planStore.Delete(sessionID)
	}

	// Build agent state with SSE callback
	state := &agent.AgentState{
		Problem:             userMsg,
		ConversationHistory: historyPrefix,
		WorkspaceDir:        h.workspaceDir,
		ToolRegistry:        reqRegistry,
		ThinkingMode:        h.thinkingMode,
		ToolCallMode:        h.toolCallMode,
		ContextWindowTokens: h.contextWindowTokens,
		OSName:              h.osName,
		ShellCmd:            h.shellCmd,
		ModelName:           h.modelName,
		OnStepComplete: func(step agent.StepRecord) {
			// Write to execution log
			if h.execLogger != nil {
				h.execLogger.LogStep(step)
			}
			switch step.Type {
			case "decide":
				sse.Send("step", step)
			case "tool":
				sse.Send("tool", step)
			case "think":
				sse.Send("step", step)
			}
		},
		OnStreamChunk: func(chunk string) {
			sse.Send("chunk", map[string]string{"text": chunk})
		},
	}

	// CostGuard: inject if configured
	if h.maxAgentTokens > 0 || h.maxAgentDuration > 0 {
		state.CostGuard = agent.NewCostGuard(h.maxAgentTokens, h.maxAgentDuration)
	}

	// ContextGuard: inject OnContextOverflow callback for auto-compact
	if sessionID != "" && h.sessionStore != nil && h.llmProvider != nil {
		sessID := sessionID // capture for closure
		state.OnContextOverflow = func(ctx context.Context) error {
			turns, existing := h.sessionStore.GetSessionContext(sessID)
			if len(turns) <= defaultCompactKeepN {
				return nil
			}
			summary, err := buildCompactSummary(ctx, h.llmProvider, turns, existing, defaultCompactKeepN)
			if err != nil {
				return err
			}
			h.sessionStore.Compact(sessID, summary, defaultCompactKeepN)
			log.Printf("[ContextGuard] Auto-compact done for session=%s", sessID)
			return nil
		}
	}

	// Run the agent flow with timeout context
	h.agentFlow.Run(ctx, state)

	// AnswerNode already synthesizes a polished answer with LLM.
	// Skip formatSolution here to avoid a redundant LLM round-trip
	// that adds 3-5s of latency with no visible benefit.
	solution := strings.TrimSpace(state.Solution)
	if solution == "" {
		solution = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›žç­”ã€‚è¯·é‡è¯•ã€‚"
	}

	sse.Send("done", sseDoneEvent{Solution: solution})
	log.Printf("[Agent] Done: %d steps, solution %d chars", len(state.StepHistory), len(solution))

	// Write execution log summary
	if h.execLogger != nil {
		h.execLogger.EndSession(state)
	}

	// Persist this turn to session history
	if sessionID != "" && h.sessionStore != nil {
		h.sessionStore.AppendTurn(sessionID, session.Turn{
			UserMsg:   userMsg,
			Assistant: solution,
			IsAgent:   true,
		})
	}
}
