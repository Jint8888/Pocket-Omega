package web

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"strings"
	"time"

	"github.com/pocketomega/pocket-omega/internal/agent"
	"github.com/pocketomega/pocket-omega/internal/core"
	"github.com/pocketomega/pocket-omega/internal/llm"
	"github.com/pocketomega/pocket-omega/internal/thinking"
	"github.com/pocketomega/pocket-omega/internal/tool"
)

const (
	maxRequestBody = 1 << 20         // 1MB max request body
	chatTimeout    = 5 * time.Minute // global timeout for chat flow
	agentTimeout   = 5 * time.Minute // global timeout for agent flow
)

// â”€â”€ SSE Writer â”€â”€

// sseWriter wraps an http.ResponseWriter with SSE event writing and
// client disconnect detection. Shared by both Chat and Agent handlers.
type sseWriter struct {
	w       http.ResponseWriter
	flusher http.Flusher
	ctx     context.Context
}

// newSSEWriter prepares SSE headers and returns a writer.
// Returns nil if streaming is not supported.
func newSSEWriter(w http.ResponseWriter, r *http.Request) *sseWriter {
	flusher, ok := w.(http.Flusher)
	if !ok {
		http.Error(w, "Streaming not supported", http.StatusInternalServerError)
		return nil
	}

	w.Header().Set("Content-Type", "text/event-stream")
	w.Header().Set("Cache-Control", "no-cache")
	w.Header().Set("Connection", "keep-alive")
	w.Header().Set("X-Accel-Buffering", "no")

	return &sseWriter{w: w, flusher: flusher, ctx: r.Context()}
}

// Send writes an SSE event. Returns false if the client has disconnected.
func (s *sseWriter) Send(event string, data interface{}) bool {
	select {
	case <-s.ctx.Done():
		return false
	default:
	}
	jsonBytes, err := json.Marshal(data)
	if err != nil {
		log.Printf("[SSE] JSON marshal error: %v", err)
		return false
	}
	if _, err := fmt.Fprintf(s.w, "event: %s\ndata: %s\n\n", event, string(jsonBytes)); err != nil {
		log.Printf("[SSE] Write error (client disconnected?): %v", err)
		return false
	}
	s.flusher.Flush()
	return true
}

// â”€â”€ Shared Solution Formatter â”€â”€

// formatSolutionPrompt is the system prompt for the solution formatting step.
const formatSolutionPrompt = `ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆæ•´ç†åŠ©æ‰‹ã€‚å°†æ¨ç†ç»“è®ºæ•´ç†ä¸ºæ¸…æ™°ã€å‹å¥½çš„æœ€ç»ˆå›ç­”ã€‚

## é£æ ¼æŒ‡å—
- ç”¨ emoji å›¾æ ‡æ ‡æ³¨ä¸åŒæ®µè½ï¼ˆå¦‚ ğŸ’¡ğŸ”ğŸ“âœ…âš ï¸ğŸ¯ğŸ“Œï¼‰ï¼Œè®©å†…å®¹æ›´ç”ŸåŠ¨
- æ­¥éª¤/æ–¹æ¡ˆç”¨æœ‰åºåˆ—è¡¨ï¼Œè¦ç‚¹ç”¨æ— åºåˆ—è¡¨
- é‡ç‚¹å…³é”®è¯ç”¨ **åŠ ç²—**
- ä»£ç /å‘½ä»¤ç”¨ä»£ç å—
- ä¿æŒè‡ªç„¶çš„å¯¹è¯è¯­æ°”ï¼Œåƒä¸€ä¸ªä¸“ä¸šä½†å‹å–„çš„åŠ©æ‰‹
- ä¿æŒè¯­è¨€ä¸ç”¨æˆ·ä¸€è‡´ï¼ˆä¸­æ–‡é—®ç”¨ä¸­æ–‡ç­”ï¼‰
- ä¸è¦æ·»åŠ "ä»¥ä¸‹æ˜¯ç­”æ¡ˆ"ä¹‹ç±»çš„å‰ç¼€ï¼Œç›´æ¥ä½œç­”
- å¦‚æœåŸå§‹ç»“è®ºå·²è¶³å¤Ÿå¥½ï¼Œç›´æ¥ä¿ç•™ä¸è¦è¿‡åº¦ä¿®é¥°

## ç¤ºä¾‹

ç”¨æˆ·é—®é¢˜ï¼šä¸€ä¸ªæˆ¿é—´é‡Œæœ‰3ç›ç¯ï¼Œæˆ¿é—´å¤–æœ‰3ä¸ªå¼€å…³ã€‚ä½ åªèƒ½è¿›å…¥æˆ¿é—´ä¸€æ¬¡ã€‚å¦‚ä½•ç¡®å®šå“ªä¸ªå¼€å…³æ§åˆ¶å“ªç›ç¯ï¼Ÿ

æ•´ç†åçš„ç­”æ¡ˆï¼š

ğŸ’¡ **æ ¸å¿ƒæ€è·¯ï¼š** åˆ©ç”¨ç¯æ³¡é€šç”µåçš„ **çƒ­æƒ°æ€§** å¼•å…¥ç¬¬ä¸‰ä¸ªåˆ¤æ–­ç»´åº¦ã€‚

ğŸ“ **æ“ä½œæ­¥éª¤ï¼š**

1. **æ‰“å¼€å¼€å…³ 1**ï¼Œä¿æŒçº¦ 5 åˆ†é’Ÿï¼Œè®©ç¯æ³¡å……åˆ†å‘çƒ­
2. **å…³é—­å¼€å…³ 1**ï¼Œç«‹å³ **æ‰“å¼€å¼€å…³ 2**
3. **è¿›å…¥æˆ¿é—´**ï¼Œè§‚å¯Ÿå¹¶è§¦æ‘¸ç¯æ³¡

ğŸ” **åˆ¤æ–­æ–¹æ³•ï¼š**

- ğŸ’¡ **äº®ç€çš„ç¯** â†’ å¼€å…³ 2 æ§åˆ¶ï¼ˆå½“å‰é€šç”µï¼‰
- ğŸ”¥ **ä¸äº®ä½†æ¸©çƒ­** â†’ å¼€å…³ 1 æ§åˆ¶ï¼ˆåˆšæ–­ç”µï¼Œä½™æ¸©å°šåœ¨ï¼‰
- â„ï¸ **ä¸äº®ä¸”å†°å‡‰** â†’ å¼€å…³ 3 æ§åˆ¶ï¼ˆä»æœªé€šç”µï¼‰

âœ… å…³é”®åœ¨äºåˆ©ç”¨ç¯æ³¡çš„çƒ­æƒ°æ€§ï¼Œå°†"åªèƒ½è¿›ä¸€æ¬¡"çš„ä¸¤æ€åˆ¤æ–­ï¼ˆäº®/ç­ï¼‰æ‰©å±•ä¸ºä¸‰æ€åˆ¤æ–­ï¼ˆäº®/æš—çƒ­/æš—å†·ï¼‰ã€‚`

// formatSolution makes a lightweight LLM call to clean and organize
// a raw conclusion into a well-structured, user-facing answer.
// Shared by both ChatHandler and AgentHandler.
func formatSolution(ctx context.Context, provider llm.LLMProvider, problem, rawSolution string) (string, error) {
	userPrompt := fmt.Sprintf("ç”¨æˆ·é—®é¢˜ï¼š%s\n\nåŸå§‹æ¨ç†ç»“è®ºï¼š\n%s\n\nè¯·æ•´ç†ä¸ºæœ€ç»ˆç­”æ¡ˆï¼š", problem, rawSolution)

	resp, err := provider.CallLLM(ctx, []llm.Message{
		{Role: llm.RoleSystem, Content: formatSolutionPrompt},
		{Role: llm.RoleUser, Content: userPrompt},
	})
	if err != nil {
		return "", fmt.Errorf("format LLM call failed: %w", err)
	}

	formatted := strings.TrimSpace(resp.Content)
	if formatted == "" {
		return "", fmt.Errorf("format returned empty response")
	}

	log.Printf("[Format] Formatted solution: %d -> %d chars", len(rawSolution), len(formatted))
	return formatted, nil
}

// â”€â”€ SSE Event Types â”€â”€

type sseThoughtEvent struct {
	ThoughtNumber   int    `json:"thought_number"`
	CurrentThinking string `json:"current_thinking"`
	PlanText        string `json:"plan_text,omitempty"`
}

type sseDoneEvent struct {
	Solution string `json:"solution"`
}

type sseErrorEvent struct {
	Error string `json:"error"`
}

// â”€â”€ Chat Handler â”€â”€

// ChatHandler handles chat requests and runs the CoT flow.
type ChatHandler struct {
	llmProvider llm.LLMProvider
	maxRetries  int
}

// NewChatHandler creates a new handler with the given LLM provider.
func NewChatHandler(provider llm.LLMProvider, maxRetries int) *ChatHandler {
	return &ChatHandler{
		llmProvider: provider,
		maxRetries:  maxRetries,
	}
}

// HandleChat processes chat POST requests using SSE streaming.
func (h *ChatHandler) HandleChat(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	r.Body = http.MaxBytesReader(w, r.Body, maxRequestBody)

	userMsg := strings.TrimSpace(r.FormValue("message"))
	if userMsg == "" {
		http.Error(w, "Empty message", http.StatusBadRequest)
		return
	}

	log.Printf("[Chat] Received: %s", userMsg)

	sse := newSSEWriter(w, r)
	if sse == nil {
		return
	}

	// Global timeout for the chat flow
	ctx, cancel := context.WithTimeout(r.Context(), chatTimeout)
	defer cancel()

	// Build and run the CoT flow with streaming callback
	flow := thinking.BuildFlow(h.llmProvider, h.maxRetries)
	state := &thinking.ThinkingState{
		Problem: userMsg,
		OnThoughtComplete: func(thought thinking.ThoughtData) {
			sse.Send("thought", sseThoughtEvent{
				ThoughtNumber:   thought.ThoughtNumber,
				CurrentThinking: strings.TrimSpace(thought.CurrentThinking),
				PlanText:        thinking.FormatPlan(thought.Planning, 0),
			})
		},
	}
	flow.Run(ctx, state)

	solution := strings.TrimSpace(state.Solution)
	if solution == "" {
		solution = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›ç­”ã€‚è¯·é‡è¯•ã€‚"
	} else {
		formatted, err := formatSolution(ctx, h.llmProvider, userMsg, solution)
		if err != nil {
			log.Printf("[Format] Formatting failed, using raw solution: %v", err)
		} else {
			solution = formatted
		}
	}

	sse.Send("done", sseDoneEvent{Solution: solution})
	log.Printf("[Chat] Done: %d thoughts, solution %d chars", len(state.Thoughts), len(solution))
}

// â”€â”€ Agent Handler (Phase 2) â”€â”€

// AgentHandler handles agent requests with tool usage capability.
type AgentHandler struct {
	llmProvider  llm.LLMProvider
	agentFlow    core.Workflow[agent.AgentState]
	toolRegistry *tool.Registry
	workspaceDir string
	execLogger   *agent.ExecLogger
	thinkingMode string
}

// NewAgentHandler creates a new agent handler.
func NewAgentHandler(provider llm.LLMProvider, registry *tool.Registry, workspaceDir string, execLogger *agent.ExecLogger, thinkingMode string) *AgentHandler {
	return &AgentHandler{
		llmProvider:  provider,
		agentFlow:    agent.BuildAgentFlow(provider, registry, thinkingMode),
		toolRegistry: registry,
		workspaceDir: workspaceDir,
		execLogger:   execLogger,
		thinkingMode: thinkingMode,
	}
}

// HandleAgent processes agent requests using SSE streaming with tool calls.
func (h *AgentHandler) HandleAgent(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	r.Body = http.MaxBytesReader(w, r.Body, maxRequestBody)

	userMsg := strings.TrimSpace(r.FormValue("message"))
	if userMsg == "" {
		http.Error(w, "Empty message", http.StatusBadRequest)
		return
	}

	log.Printf("[Agent] Received: %s", userMsg)

	sse := newSSEWriter(w, r)
	if sse == nil {
		return
	}

	// Global timeout for the entire agent flow
	ctx, cancel := context.WithTimeout(r.Context(), agentTimeout)
	defer cancel()

	// Send immediate status so user sees instant feedback
	sse.Send("status", map[string]string{"message": "ğŸ¤” æ­£åœ¨åˆ†æé—®é¢˜..."})

	// Start execution log session
	if h.execLogger != nil {
		h.execLogger.StartSession(userMsg)
	}

	// Build agent state with SSE callback
	state := &agent.AgentState{
		Problem:      userMsg,
		WorkspaceDir: h.workspaceDir,
		ToolRegistry: h.toolRegistry,
		ThinkingMode: h.thinkingMode,
		OnStepComplete: func(step agent.StepRecord) {
			// Write to execution log
			if h.execLogger != nil {
				h.execLogger.LogStep(step)
			}
			switch step.Type {
			case "decide":
				sse.Send("step", step)
			case "tool":
				sse.Send("tool", step)
			case "think":
				sse.Send("step", step)
			}
		},
		OnStreamChunk: func(chunk string) {
			sse.Send("chunk", map[string]string{"text": chunk})
		},
	}

	// Run the agent flow with timeout context
	h.agentFlow.Run(ctx, state)

	// AnswerNode already synthesizes a polished answer with LLM.
	// Skip formatSolution here to avoid a redundant LLM round-trip
	// that adds 3-5s of latency with no visible benefit.
	solution := strings.TrimSpace(state.Solution)
	if solution == "" {
		solution = "æŠ±æ­‰ï¼Œæœªèƒ½ç”Ÿæˆå›ç­”ã€‚è¯·é‡è¯•ã€‚"
	}

	sse.Send("done", sseDoneEvent{Solution: solution})
	log.Printf("[Agent] Done: %d steps, solution %d chars", len(state.StepHistory), len(solution))

	// Write execution log summary
	if h.execLogger != nil {
		h.execLogger.EndSession(state)
	}
}
